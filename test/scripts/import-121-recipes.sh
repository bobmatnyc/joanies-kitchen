#!/bin/bash
# Standalone Firecrawl import using curl to call Next.js API route

echo "ğŸš€ Starting batch import of 121 chef recipes"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

# Read URLs from file
URLS_FILE="tmp/urls-to-import.txt"
TOTAL=$(wc -l < "$URLS_FILE")
COUNT=0
SUCCESS=0
FAIL=0

echo "ğŸ“Š Total URLs to process: $TOTAL"
echo ""

# Process each URL
while IFS= read -r url; do
    COUNT=$((COUNT + 1))
    echo "[$COUNT/$TOTAL] Processing: $url"

    # Call the recipe-crawl API endpoint
    response=$(curl -s -X POST http://localhost:3002/api/recipe-crawl \
        -H "Content-Type: application/json" \
        -d "{\"url\":\"$url\"}" \
        --max-time 60)

    if echo "$response" | grep -q '"success":true'; then
        SUCCESS=$((SUCCESS + 1))
        echo "  âœ… Success"
    else
        FAIL=$((FAIL + 1))
        echo "  âŒ Failed"
    fi

    # Rate limiting: 2 seconds between requests
    if [ $COUNT -lt $TOTAL ]; then
        sleep 2
    fi
done < "$URLS_FILE"

echo ""
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "ğŸ“Š Import Complete"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "âœ… Successful: $SUCCESS"
echo "âŒ Failed: $FAIL"
echo "ğŸ“ˆ Success rate: $(awk "BEGIN {printf \"%.1f\", ($SUCCESS/($SUCCESS+$FAIL))*100}")%"
